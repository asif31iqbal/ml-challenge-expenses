{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with deep learning\n",
    "\n",
    "The classification solution tries to address the problem using deep learning. I just tried it out of curiosity:\n",
    "\n",
    "*Train a learning model that assigns each expense transaction to one of the set of predefined categories and evaluate it against the validation data provided. The set of categories are those found in the \"category\" column in the training data. Report on accuracy and at least one other performance metric.*\n",
    "\n",
    "For this, I tried the following:\n",
    "- **Using a simple 3-layer ANN with all features (non-text and text, with text vectorized using scikit learn's TfIdfVectorizer)**\n",
    "- **Using a simple 3-layer ANN with only text features (with text vectorized using Keras's text to matrix binary vectorizer)**\n",
    "- **Using a RNN with LSTM with a pre-trained embedding layer and only text features (with text vectorized using Keras's text to matrix binary vectorizer)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from keras import models, layers\n",
    "from keras.utils import np_utils\n",
    "from keras import preprocessing as kreprocessing\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data nd preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('training_data_example.csv')\n",
    "df_val = pd.read_csv('validation_data_example.csv')\n",
    "df_employee = pd.read_csv('employee.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df, columns_to_drop=['date',\n",
    "                                    'category', \n",
    "                                    'tax amount',                                 \n",
    "                                    'expense description']):\n",
    "    \n",
    "    df['day_of_week'] = pd.to_datetime(df['date']).apply(lambda x: x.weekday()).astype(str) # str so that treated as categoical\n",
    "    df['month'] = pd.to_datetime(df['date']).apply(lambda x: x.month).astype(str)\n",
    "    df = pd.merge(df, df_employee[['employee id', 'role']], how='inner', on=['employee id'])\n",
    "    df['employee id'] = df['employee id'].astype(str)\n",
    "    df = df.drop(columns_to_drop, axis=1)\n",
    "    \n",
    "    # one-hot encode the categorical variables\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    df['pre-tax amount'] = preprocessing.minmax_scale(df[['pre-tax amount']])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ready the pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pre_process(df_train)\n",
    "x_val = pre_process(df_val)\n",
    "x_train, x_val = x_train.align(x_val, join='left', axis=1)\n",
    "x_val = x_val.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process text features separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "vectorizer.fit(df_train['expense description'])\n",
    "x_train_tfidf = vectorizer.transform(df_train['expense description']).toarray()\n",
    "x_val_tfidf = vectorizer.transform(df_val['expense description']).toarray()\n",
    "# x_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate text and non-text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((x_train.values, x_train_tfidf), axis=1)\n",
    "x_val = np.concatenate((x_val.values, x_val_tfidf), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate vectorized output labels for feeding to Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "lencoder = LabelEncoder()\n",
    "lencoder.fit(df_train['category'])\n",
    "names = set(df_val['category']) # label names to be used later\n",
    "y_train = lencoder.transform(df_train['category'])\n",
    "y_val = lencoder.transform(df_val['category'])\n",
    "dummy_y_train = np_utils.to_categorical(y_train)\n",
    "dummy_y_val = np_utils.to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1\n",
    "\n",
    "### Using a simple 3-layer ANN with all features (non-text and text, with text vectorized using scikit learn's TfIdfVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_41 (Dense)             (None, 16)                832       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 1,189\n",
      "Trainable params: 1,189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24 samples, validate on 12 samples\n",
      "Epoch 1/200\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.6079 - acc: 0.1250 - val_loss: 1.6118 - val_acc: 0.2500\n",
      "Epoch 2/200\n",
      "24/24 [==============================] - 0s 324us/step - loss: 1.5794 - acc: 0.1667 - val_loss: 1.6026 - val_acc: 0.1667\n",
      "Epoch 3/200\n",
      "24/24 [==============================] - 0s 628us/step - loss: 1.5615 - acc: 0.2500 - val_loss: 1.5947 - val_acc: 0.1667\n",
      "Epoch 4/200\n",
      "24/24 [==============================] - 0s 308us/step - loss: 1.5471 - acc: 0.2500 - val_loss: 1.5873 - val_acc: 0.0833\n",
      "Epoch 5/200\n",
      "24/24 [==============================] - 0s 332us/step - loss: 1.5331 - acc: 0.3333 - val_loss: 1.5800 - val_acc: 0.1667\n",
      "Epoch 6/200\n",
      "24/24 [==============================] - 0s 526us/step - loss: 1.5206 - acc: 0.4167 - val_loss: 1.5730 - val_acc: 0.3333\n",
      "Epoch 7/200\n",
      "24/24 [==============================] - 0s 418us/step - loss: 1.5087 - acc: 0.5000 - val_loss: 1.5665 - val_acc: 0.3333\n",
      "Epoch 8/200\n",
      "24/24 [==============================] - 0s 356us/step - loss: 1.4968 - acc: 0.5417 - val_loss: 1.5605 - val_acc: 0.3333\n",
      "Epoch 9/200\n",
      "24/24 [==============================] - 0s 360us/step - loss: 1.4858 - acc: 0.5417 - val_loss: 1.5542 - val_acc: 0.3333\n",
      "Epoch 10/200\n",
      "24/24 [==============================] - 0s 613us/step - loss: 1.4756 - acc: 0.5417 - val_loss: 1.5484 - val_acc: 0.3333\n",
      "Epoch 11/200\n",
      "24/24 [==============================] - 0s 448us/step - loss: 1.4647 - acc: 0.5833 - val_loss: 1.5417 - val_acc: 0.3333\n",
      "Epoch 12/200\n",
      "24/24 [==============================] - 0s 355us/step - loss: 1.4539 - acc: 0.6667 - val_loss: 1.5359 - val_acc: 0.3333\n",
      "Epoch 13/200\n",
      "24/24 [==============================] - 0s 406us/step - loss: 1.4429 - acc: 0.6667 - val_loss: 1.5299 - val_acc: 0.3333\n",
      "Epoch 14/200\n",
      "24/24 [==============================] - 0s 482us/step - loss: 1.4333 - acc: 0.6667 - val_loss: 1.5245 - val_acc: 0.3333\n",
      "Epoch 15/200\n",
      "24/24 [==============================] - 0s 369us/step - loss: 1.4225 - acc: 0.7083 - val_loss: 1.5188 - val_acc: 0.3333\n",
      "Epoch 16/200\n",
      "24/24 [==============================] - 0s 405us/step - loss: 1.4113 - acc: 0.7083 - val_loss: 1.5120 - val_acc: 0.4167\n",
      "Epoch 17/200\n",
      "24/24 [==============================] - 0s 307us/step - loss: 1.3995 - acc: 0.7083 - val_loss: 1.5059 - val_acc: 0.4167\n",
      "Epoch 18/200\n",
      "24/24 [==============================] - 0s 731us/step - loss: 1.3887 - acc: 0.7083 - val_loss: 1.4990 - val_acc: 0.4167\n",
      "Epoch 19/200\n",
      "24/24 [==============================] - 0s 701us/step - loss: 1.3771 - acc: 0.7083 - val_loss: 1.4930 - val_acc: 0.4167\n",
      "Epoch 20/200\n",
      "24/24 [==============================] - 0s 350us/step - loss: 1.3654 - acc: 0.7083 - val_loss: 1.4860 - val_acc: 0.4167\n",
      "Epoch 21/200\n",
      "24/24 [==============================] - 0s 367us/step - loss: 1.3550 - acc: 0.6667 - val_loss: 1.4799 - val_acc: 0.4167\n",
      "Epoch 22/200\n",
      "24/24 [==============================] - 0s 463us/step - loss: 1.3417 - acc: 0.6667 - val_loss: 1.4741 - val_acc: 0.4167\n",
      "Epoch 23/200\n",
      "24/24 [==============================] - 0s 819us/step - loss: 1.3302 - acc: 0.7083 - val_loss: 1.4678 - val_acc: 0.4167\n",
      "Epoch 24/200\n",
      "24/24 [==============================] - 0s 380us/step - loss: 1.3184 - acc: 0.6667 - val_loss: 1.4626 - val_acc: 0.4167\n",
      "Epoch 25/200\n",
      "24/24 [==============================] - 0s 540us/step - loss: 1.3059 - acc: 0.6667 - val_loss: 1.4568 - val_acc: 0.4167\n",
      "Epoch 26/200\n",
      "24/24 [==============================] - 0s 343us/step - loss: 1.2939 - acc: 0.6667 - val_loss: 1.4512 - val_acc: 0.4167\n",
      "Epoch 27/200\n",
      "24/24 [==============================] - 0s 327us/step - loss: 1.2812 - acc: 0.6667 - val_loss: 1.4447 - val_acc: 0.4167\n",
      "Epoch 28/200\n",
      "24/24 [==============================] - 0s 702us/step - loss: 1.2698 - acc: 0.6667 - val_loss: 1.4383 - val_acc: 0.4167\n",
      "Epoch 29/200\n",
      "24/24 [==============================] - 0s 541us/step - loss: 1.2571 - acc: 0.6667 - val_loss: 1.4322 - val_acc: 0.4167\n",
      "Epoch 30/200\n",
      "24/24 [==============================] - 0s 683us/step - loss: 1.2446 - acc: 0.6667 - val_loss: 1.4262 - val_acc: 0.4167\n",
      "Epoch 31/200\n",
      "24/24 [==============================] - 0s 420us/step - loss: 1.2309 - acc: 0.6667 - val_loss: 1.4195 - val_acc: 0.4167\n",
      "Epoch 32/200\n",
      "24/24 [==============================] - 0s 498us/step - loss: 1.2181 - acc: 0.6667 - val_loss: 1.4136 - val_acc: 0.4167\n",
      "Epoch 33/200\n",
      "24/24 [==============================] - 0s 540us/step - loss: 1.2051 - acc: 0.7500 - val_loss: 1.4061 - val_acc: 0.4167\n",
      "Epoch 34/200\n",
      "24/24 [==============================] - 0s 524us/step - loss: 1.1915 - acc: 0.7500 - val_loss: 1.3990 - val_acc: 0.5000\n",
      "Epoch 35/200\n",
      "24/24 [==============================] - 0s 421us/step - loss: 1.1790 - acc: 0.7500 - val_loss: 1.3922 - val_acc: 0.5000\n",
      "Epoch 36/200\n",
      "24/24 [==============================] - 0s 504us/step - loss: 1.1661 - acc: 0.7500 - val_loss: 1.3858 - val_acc: 0.5000\n",
      "Epoch 37/200\n",
      "24/24 [==============================] - 0s 332us/step - loss: 1.1545 - acc: 0.7500 - val_loss: 1.3784 - val_acc: 0.5000\n",
      "Epoch 38/200\n",
      "24/24 [==============================] - 0s 321us/step - loss: 1.1399 - acc: 0.7500 - val_loss: 1.3726 - val_acc: 0.5000\n",
      "Epoch 39/200\n",
      "24/24 [==============================] - 0s 336us/step - loss: 1.1271 - acc: 0.7500 - val_loss: 1.3643 - val_acc: 0.5000\n",
      "Epoch 40/200\n",
      "24/24 [==============================] - 0s 369us/step - loss: 1.1138 - acc: 0.7500 - val_loss: 1.3584 - val_acc: 0.5000\n",
      "Epoch 41/200\n",
      "24/24 [==============================] - 0s 319us/step - loss: 1.1013 - acc: 0.7500 - val_loss: 1.3498 - val_acc: 0.5000\n",
      "Epoch 42/200\n",
      "24/24 [==============================] - 0s 782us/step - loss: 1.0882 - acc: 0.7500 - val_loss: 1.3421 - val_acc: 0.5000\n",
      "Epoch 43/200\n",
      "24/24 [==============================] - 0s 496us/step - loss: 1.0741 - acc: 0.7500 - val_loss: 1.3357 - val_acc: 0.5000\n",
      "Epoch 44/200\n",
      "24/24 [==============================] - 0s 319us/step - loss: 1.0617 - acc: 0.7500 - val_loss: 1.3271 - val_acc: 0.5000\n",
      "Epoch 45/200\n",
      "24/24 [==============================] - 0s 469us/step - loss: 1.0495 - acc: 0.7500 - val_loss: 1.3207 - val_acc: 0.5833\n",
      "Epoch 46/200\n",
      "24/24 [==============================] - 0s 402us/step - loss: 1.0349 - acc: 0.7500 - val_loss: 1.3127 - val_acc: 0.5833\n",
      "Epoch 47/200\n",
      "24/24 [==============================] - 0s 255us/step - loss: 1.0206 - acc: 0.7500 - val_loss: 1.3062 - val_acc: 0.5833\n",
      "Epoch 48/200\n",
      "24/24 [==============================] - 0s 438us/step - loss: 1.0073 - acc: 0.7500 - val_loss: 1.2981 - val_acc: 0.5833\n",
      "Epoch 49/200\n",
      "24/24 [==============================] - 0s 638us/step - loss: 0.9942 - acc: 0.7500 - val_loss: 1.2908 - val_acc: 0.5833\n",
      "Epoch 50/200\n",
      "24/24 [==============================] - 0s 496us/step - loss: 0.9811 - acc: 0.7500 - val_loss: 1.2840 - val_acc: 0.5833\n",
      "Epoch 51/200\n",
      "24/24 [==============================] - 0s 438us/step - loss: 0.9669 - acc: 0.7500 - val_loss: 1.2786 - val_acc: 0.5833\n",
      "Epoch 52/200\n",
      "24/24 [==============================] - 0s 495us/step - loss: 0.9537 - acc: 0.7500 - val_loss: 1.2702 - val_acc: 0.5833\n",
      "Epoch 53/200\n",
      "24/24 [==============================] - 0s 263us/step - loss: 0.9392 - acc: 0.7500 - val_loss: 1.2642 - val_acc: 0.5833\n",
      "Epoch 54/200\n",
      "24/24 [==============================] - 0s 319us/step - loss: 0.9267 - acc: 0.7500 - val_loss: 1.2581 - val_acc: 0.6667\n",
      "Epoch 55/200\n",
      "24/24 [==============================] - 0s 221us/step - loss: 0.9144 - acc: 0.7500 - val_loss: 1.2505 - val_acc: 0.6667\n",
      "Epoch 56/200\n",
      "24/24 [==============================] - 0s 555us/step - loss: 0.9016 - acc: 0.7500 - val_loss: 1.2450 - val_acc: 0.6667\n",
      "Epoch 57/200\n",
      "24/24 [==============================] - 0s 762us/step - loss: 0.8887 - acc: 0.7500 - val_loss: 1.2379 - val_acc: 0.7500\n",
      "Epoch 58/200\n",
      "24/24 [==============================] - 0s 415us/step - loss: 0.8761 - acc: 0.7500 - val_loss: 1.2339 - val_acc: 0.7500\n",
      "Epoch 59/200\n",
      "24/24 [==============================] - 0s 384us/step - loss: 0.8638 - acc: 0.7917 - val_loss: 1.2275 - val_acc: 0.7500\n",
      "Epoch 60/200\n",
      "24/24 [==============================] - 0s 329us/step - loss: 0.8512 - acc: 0.7917 - val_loss: 1.2225 - val_acc: 0.7500\n",
      "Epoch 61/200\n",
      "24/24 [==============================] - 0s 379us/step - loss: 0.8383 - acc: 0.7917 - val_loss: 1.2165 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "24/24 [==============================] - 0s 343us/step - loss: 0.8262 - acc: 0.7917 - val_loss: 1.2089 - val_acc: 0.7500\n",
      "Epoch 63/200\n",
      "24/24 [==============================] - 0s 370us/step - loss: 0.8135 - acc: 0.7917 - val_loss: 1.2033 - val_acc: 0.7500\n",
      "Epoch 64/200\n",
      "24/24 [==============================] - 0s 388us/step - loss: 0.8055 - acc: 0.7917 - val_loss: 1.1976 - val_acc: 0.7500\n",
      "Epoch 65/200\n",
      "24/24 [==============================] - 0s 627us/step - loss: 0.7914 - acc: 0.7917 - val_loss: 1.1922 - val_acc: 0.7500\n",
      "Epoch 66/200\n",
      "24/24 [==============================] - 0s 387us/step - loss: 0.7783 - acc: 0.7917 - val_loss: 1.1860 - val_acc: 0.7500\n",
      "Epoch 67/200\n",
      "24/24 [==============================] - 0s 574us/step - loss: 0.7668 - acc: 0.7917 - val_loss: 1.1800 - val_acc: 0.7500\n",
      "Epoch 68/200\n",
      "24/24 [==============================] - 0s 320us/step - loss: 0.7555 - acc: 0.7917 - val_loss: 1.1744 - val_acc: 0.7500\n",
      "Epoch 69/200\n",
      "24/24 [==============================] - 0s 361us/step - loss: 0.7468 - acc: 0.7917 - val_loss: 1.1689 - val_acc: 0.7500\n",
      "Epoch 70/200\n",
      "24/24 [==============================] - 0s 420us/step - loss: 0.7328 - acc: 0.7917 - val_loss: 1.1607 - val_acc: 0.7500\n",
      "Epoch 71/200\n",
      "24/24 [==============================] - 0s 296us/step - loss: 0.7213 - acc: 0.7917 - val_loss: 1.1567 - val_acc: 0.7500\n",
      "Epoch 72/200\n",
      "24/24 [==============================] - 0s 866us/step - loss: 0.7099 - acc: 0.7917 - val_loss: 1.1496 - val_acc: 0.7500\n",
      "Epoch 73/200\n",
      "24/24 [==============================] - 0s 357us/step - loss: 0.6982 - acc: 0.7917 - val_loss: 1.1448 - val_acc: 0.7500\n",
      "Epoch 74/200\n",
      "24/24 [==============================] - 0s 340us/step - loss: 0.6875 - acc: 0.7917 - val_loss: 1.1381 - val_acc: 0.7500\n",
      "Epoch 75/200\n",
      "24/24 [==============================] - 0s 413us/step - loss: 0.6797 - acc: 0.7917 - val_loss: 1.1351 - val_acc: 0.7500\n",
      "Epoch 76/200\n",
      "24/24 [==============================] - 0s 528us/step - loss: 0.6659 - acc: 0.8333 - val_loss: 1.1267 - val_acc: 0.7500\n",
      "Epoch 77/200\n",
      "24/24 [==============================] - 0s 458us/step - loss: 0.6556 - acc: 0.8333 - val_loss: 1.1212 - val_acc: 0.7500\n",
      "Epoch 78/200\n",
      "24/24 [==============================] - 0s 852us/step - loss: 0.6444 - acc: 0.8333 - val_loss: 1.1155 - val_acc: 0.7500\n",
      "Epoch 79/200\n",
      "24/24 [==============================] - 0s 516us/step - loss: 0.6357 - acc: 0.8333 - val_loss: 1.1101 - val_acc: 0.7500\n",
      "Epoch 80/200\n",
      "24/24 [==============================] - 0s 589us/step - loss: 0.6257 - acc: 0.8333 - val_loss: 1.1045 - val_acc: 0.7500\n",
      "Epoch 81/200\n",
      "24/24 [==============================] - 0s 411us/step - loss: 0.6141 - acc: 0.8333 - val_loss: 1.0982 - val_acc: 0.7500\n",
      "Epoch 82/200\n",
      "24/24 [==============================] - 0s 384us/step - loss: 0.6039 - acc: 0.8333 - val_loss: 1.0911 - val_acc: 0.7500\n",
      "Epoch 83/200\n",
      "24/24 [==============================] - 0s 625us/step - loss: 0.5952 - acc: 0.8333 - val_loss: 1.0852 - val_acc: 0.7500\n",
      "Epoch 84/200\n",
      "24/24 [==============================] - 0s 380us/step - loss: 0.5864 - acc: 0.8333 - val_loss: 1.0775 - val_acc: 0.7500\n",
      "Epoch 85/200\n",
      "24/24 [==============================] - 0s 419us/step - loss: 0.5750 - acc: 0.8333 - val_loss: 1.0734 - val_acc: 0.7500\n",
      "Epoch 86/200\n",
      "24/24 [==============================] - 0s 705us/step - loss: 0.5669 - acc: 0.8333 - val_loss: 1.0660 - val_acc: 0.7500\n",
      "Epoch 87/200\n",
      "24/24 [==============================] - 0s 394us/step - loss: 0.5572 - acc: 0.8750 - val_loss: 1.0601 - val_acc: 0.7500\n",
      "Epoch 88/200\n",
      "24/24 [==============================] - 0s 337us/step - loss: 0.5493 - acc: 0.8750 - val_loss: 1.0527 - val_acc: 0.7500\n",
      "Epoch 89/200\n",
      "24/24 [==============================] - 0s 382us/step - loss: 0.5376 - acc: 0.8750 - val_loss: 1.0475 - val_acc: 0.7500\n",
      "Epoch 90/200\n",
      "24/24 [==============================] - 0s 465us/step - loss: 0.5295 - acc: 0.8750 - val_loss: 1.0411 - val_acc: 0.7500\n",
      "Epoch 91/200\n",
      "24/24 [==============================] - 0s 295us/step - loss: 0.5213 - acc: 0.8750 - val_loss: 1.0355 - val_acc: 0.7500\n",
      "Epoch 92/200\n",
      "24/24 [==============================] - 0s 397us/step - loss: 0.5130 - acc: 0.8750 - val_loss: 1.0286 - val_acc: 0.7500\n",
      "Epoch 93/200\n",
      "24/24 [==============================] - 0s 511us/step - loss: 0.5051 - acc: 0.8750 - val_loss: 1.0214 - val_acc: 0.7500\n",
      "Epoch 94/200\n",
      "24/24 [==============================] - 0s 418us/step - loss: 0.4962 - acc: 0.8750 - val_loss: 1.0162 - val_acc: 0.7500\n",
      "Epoch 95/200\n",
      "24/24 [==============================] - 0s 352us/step - loss: 0.4881 - acc: 0.8750 - val_loss: 1.0086 - val_acc: 0.7500\n",
      "Epoch 96/200\n",
      "24/24 [==============================] - 0s 425us/step - loss: 0.4792 - acc: 0.8750 - val_loss: 1.0036 - val_acc: 0.7500\n",
      "Epoch 97/200\n",
      "24/24 [==============================] - 0s 479us/step - loss: 0.4725 - acc: 0.8750 - val_loss: 0.9984 - val_acc: 0.8333\n",
      "Epoch 98/200\n",
      "24/24 [==============================] - 0s 503us/step - loss: 0.4638 - acc: 0.8750 - val_loss: 0.9900 - val_acc: 0.8333\n",
      "Epoch 99/200\n",
      "24/24 [==============================] - 0s 474us/step - loss: 0.4560 - acc: 0.8750 - val_loss: 0.9833 - val_acc: 0.8333\n",
      "Epoch 100/200\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.4489 - acc: 0.8750 - val_loss: 0.9770 - val_acc: 0.8333\n",
      "Epoch 101/200\n",
      "24/24 [==============================] - 0s 639us/step - loss: 0.4408 - acc: 0.8750 - val_loss: 0.9710 - val_acc: 0.8333\n",
      "Epoch 102/200\n",
      "24/24 [==============================] - 0s 380us/step - loss: 0.4337 - acc: 0.8750 - val_loss: 0.9644 - val_acc: 0.8333\n",
      "Epoch 103/200\n",
      "24/24 [==============================] - 0s 822us/step - loss: 0.4253 - acc: 0.8750 - val_loss: 0.9604 - val_acc: 0.8333\n",
      "Epoch 104/200\n",
      "24/24 [==============================] - 0s 539us/step - loss: 0.4188 - acc: 0.8750 - val_loss: 0.9540 - val_acc: 0.9167\n",
      "Epoch 105/200\n",
      "24/24 [==============================] - 0s 367us/step - loss: 0.4109 - acc: 0.8750 - val_loss: 0.9490 - val_acc: 0.9167\n",
      "Epoch 106/200\n",
      "24/24 [==============================] - 0s 719us/step - loss: 0.4028 - acc: 0.8750 - val_loss: 0.9427 - val_acc: 0.9167\n",
      "Epoch 107/200\n",
      "24/24 [==============================] - 0s 474us/step - loss: 0.3953 - acc: 0.8750 - val_loss: 0.9407 - val_acc: 0.9167\n",
      "Epoch 108/200\n",
      "24/24 [==============================] - 0s 443us/step - loss: 0.3887 - acc: 0.9167 - val_loss: 0.9317 - val_acc: 0.9167\n",
      "Epoch 109/200\n",
      "24/24 [==============================] - 0s 443us/step - loss: 0.3816 - acc: 0.9167 - val_loss: 0.9285 - val_acc: 0.9167\n",
      "Epoch 110/200\n",
      "24/24 [==============================] - 0s 448us/step - loss: 0.3745 - acc: 0.9167 - val_loss: 0.9210 - val_acc: 0.9167\n",
      "Epoch 111/200\n",
      "24/24 [==============================] - 0s 811us/step - loss: 0.3676 - acc: 0.9167 - val_loss: 0.9191 - val_acc: 0.9167\n",
      "Epoch 112/200\n",
      "24/24 [==============================] - 0s 489us/step - loss: 0.3615 - acc: 0.9167 - val_loss: 0.9133 - val_acc: 0.9167\n",
      "Epoch 113/200\n",
      "24/24 [==============================] - 0s 424us/step - loss: 0.3550 - acc: 0.9167 - val_loss: 0.9074 - val_acc: 0.9167\n",
      "Epoch 114/200\n",
      "24/24 [==============================] - 0s 360us/step - loss: 0.3492 - acc: 0.9167 - val_loss: 0.9029 - val_acc: 0.9167\n",
      "Epoch 115/200\n",
      "24/24 [==============================] - 0s 399us/step - loss: 0.3417 - acc: 0.9167 - val_loss: 0.8994 - val_acc: 0.9167\n",
      "Epoch 116/200\n",
      "24/24 [==============================] - 0s 446us/step - loss: 0.3356 - acc: 0.9167 - val_loss: 0.8948 - val_acc: 0.9167\n",
      "Epoch 117/200\n",
      "24/24 [==============================] - 0s 371us/step - loss: 0.3303 - acc: 0.9167 - val_loss: 0.8882 - val_acc: 0.9167\n",
      "Epoch 118/200\n",
      "24/24 [==============================] - 0s 788us/step - loss: 0.3243 - acc: 0.9167 - val_loss: 0.8842 - val_acc: 0.9167\n",
      "Epoch 119/200\n",
      "24/24 [==============================] - 0s 700us/step - loss: 0.3182 - acc: 0.9167 - val_loss: 0.8811 - val_acc: 0.9167\n",
      "Epoch 120/200\n",
      "24/24 [==============================] - 0s 382us/step - loss: 0.3146 - acc: 0.9167 - val_loss: 0.8740 - val_acc: 0.9167\n",
      "Epoch 121/200\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.4652 - acc: 0.833 - 0s 362us/step - loss: 0.3084 - acc: 0.9167 - val_loss: 0.8698 - val_acc: 0.9167\n",
      "Epoch 122/200\n",
      "24/24 [==============================] - 0s 490us/step - loss: 0.3013 - acc: 0.9167 - val_loss: 0.8648 - val_acc: 0.9167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "24/24 [==============================] - 0s 421us/step - loss: 0.2979 - acc: 0.9167 - val_loss: 0.8615 - val_acc: 0.9167\n",
      "Epoch 124/200\n",
      "24/24 [==============================] - 0s 385us/step - loss: 0.2916 - acc: 0.9167 - val_loss: 0.8556 - val_acc: 0.9167\n",
      "Epoch 125/200\n",
      "24/24 [==============================] - 0s 338us/step - loss: 0.2864 - acc: 0.9167 - val_loss: 0.8518 - val_acc: 0.9167\n",
      "Epoch 126/200\n",
      "24/24 [==============================] - 0s 312us/step - loss: 0.2819 - acc: 0.9167 - val_loss: 0.8474 - val_acc: 0.9167\n",
      "Epoch 127/200\n",
      "24/24 [==============================] - 0s 409us/step - loss: 0.2782 - acc: 0.9167 - val_loss: 0.8433 - val_acc: 0.9167\n",
      "Epoch 128/200\n",
      "24/24 [==============================] - 0s 501us/step - loss: 0.2715 - acc: 0.9167 - val_loss: 0.8398 - val_acc: 0.9167\n",
      "Epoch 129/200\n",
      "24/24 [==============================] - 0s 447us/step - loss: 0.2680 - acc: 0.9167 - val_loss: 0.8374 - val_acc: 0.9167\n",
      "Epoch 130/200\n",
      "24/24 [==============================] - 0s 598us/step - loss: 0.2627 - acc: 0.9167 - val_loss: 0.8339 - val_acc: 0.9167\n",
      "Epoch 131/200\n",
      "24/24 [==============================] - 0s 621us/step - loss: 0.2586 - acc: 0.9167 - val_loss: 0.8279 - val_acc: 0.9167\n",
      "Epoch 132/200\n",
      "24/24 [==============================] - 0s 472us/step - loss: 0.2541 - acc: 0.9167 - val_loss: 0.8279 - val_acc: 0.9167\n",
      "Epoch 133/200\n",
      "24/24 [==============================] - 0s 472us/step - loss: 0.2496 - acc: 0.9167 - val_loss: 0.8252 - val_acc: 0.9167\n",
      "Epoch 134/200\n",
      "24/24 [==============================] - 0s 316us/step - loss: 0.2458 - acc: 0.9167 - val_loss: 0.8224 - val_acc: 0.9167\n",
      "Epoch 135/200\n",
      "24/24 [==============================] - 0s 663us/step - loss: 0.2417 - acc: 0.9167 - val_loss: 0.8204 - val_acc: 0.9167\n",
      "Epoch 136/200\n",
      "24/24 [==============================] - 0s 591us/step - loss: 0.2382 - acc: 0.9583 - val_loss: 0.8147 - val_acc: 0.9167\n",
      "Epoch 137/200\n",
      "24/24 [==============================] - 0s 580us/step - loss: 0.2338 - acc: 0.9167 - val_loss: 0.8118 - val_acc: 0.9167\n",
      "Epoch 138/200\n",
      "24/24 [==============================] - 0s 713us/step - loss: 0.2293 - acc: 0.9583 - val_loss: 0.8101 - val_acc: 0.9167\n",
      "Epoch 139/200\n",
      "24/24 [==============================] - 0s 348us/step - loss: 0.2257 - acc: 0.9583 - val_loss: 0.8033 - val_acc: 0.9167\n",
      "Epoch 140/200\n",
      "24/24 [==============================] - 0s 427us/step - loss: 0.2217 - acc: 0.9583 - val_loss: 0.8001 - val_acc: 0.9167\n",
      "Epoch 141/200\n",
      "24/24 [==============================] - 0s 704us/step - loss: 0.2174 - acc: 0.9583 - val_loss: 0.7977 - val_acc: 0.9167\n",
      "Epoch 142/200\n",
      "24/24 [==============================] - 0s 541us/step - loss: 0.2133 - acc: 0.9583 - val_loss: 0.7951 - val_acc: 0.9167\n",
      "Epoch 143/200\n",
      "24/24 [==============================] - 0s 627us/step - loss: 0.2097 - acc: 0.9583 - val_loss: 0.7919 - val_acc: 0.9167\n",
      "Epoch 144/200\n",
      "24/24 [==============================] - 0s 636us/step - loss: 0.2060 - acc: 0.9583 - val_loss: 0.7887 - val_acc: 0.9167\n",
      "Epoch 145/200\n",
      "24/24 [==============================] - 0s 522us/step - loss: 0.2036 - acc: 0.9583 - val_loss: 0.7865 - val_acc: 0.9167\n",
      "Epoch 146/200\n",
      "24/24 [==============================] - 0s 541us/step - loss: 0.1991 - acc: 0.9583 - val_loss: 0.7828 - val_acc: 0.9167\n",
      "Epoch 147/200\n",
      "24/24 [==============================] - 0s 682us/step - loss: 0.1967 - acc: 0.9583 - val_loss: 0.7788 - val_acc: 0.9167\n",
      "Epoch 148/200\n",
      "24/24 [==============================] - 0s 497us/step - loss: 0.1919 - acc: 0.9583 - val_loss: 0.7723 - val_acc: 0.9167\n",
      "Epoch 149/200\n",
      "24/24 [==============================] - 0s 353us/step - loss: 0.1895 - acc: 0.9583 - val_loss: 0.7723 - val_acc: 0.9167\n",
      "Epoch 150/200\n",
      "24/24 [==============================] - 0s 442us/step - loss: 0.1864 - acc: 0.9583 - val_loss: 0.7683 - val_acc: 0.9167\n",
      "Epoch 151/200\n",
      "24/24 [==============================] - 0s 487us/step - loss: 0.1822 - acc: 0.9583 - val_loss: 0.7642 - val_acc: 0.9167\n",
      "Epoch 152/200\n",
      "24/24 [==============================] - 0s 486us/step - loss: 0.1792 - acc: 0.9583 - val_loss: 0.7616 - val_acc: 0.9167\n",
      "Epoch 153/200\n",
      "24/24 [==============================] - 0s 393us/step - loss: 0.1770 - acc: 0.9583 - val_loss: 0.7577 - val_acc: 0.9167\n",
      "Epoch 154/200\n",
      "24/24 [==============================] - 0s 373us/step - loss: 0.1732 - acc: 0.9583 - val_loss: 0.7556 - val_acc: 0.9167\n",
      "Epoch 155/200\n",
      "24/24 [==============================] - 0s 808us/step - loss: 0.1696 - acc: 0.9583 - val_loss: 0.7536 - val_acc: 0.9167\n",
      "Epoch 156/200\n",
      "24/24 [==============================] - 0s 517us/step - loss: 0.1673 - acc: 0.9583 - val_loss: 0.7518 - val_acc: 0.9167\n",
      "Epoch 157/200\n",
      "24/24 [==============================] - 0s 415us/step - loss: 0.1638 - acc: 0.9583 - val_loss: 0.7474 - val_acc: 0.9167\n",
      "Epoch 158/200\n",
      "24/24 [==============================] - 0s 354us/step - loss: 0.1612 - acc: 0.9583 - val_loss: 0.7453 - val_acc: 0.9167\n",
      "Epoch 159/200\n",
      "24/24 [==============================] - 0s 401us/step - loss: 0.1580 - acc: 0.9583 - val_loss: 0.7397 - val_acc: 0.9167\n",
      "Epoch 160/200\n",
      "24/24 [==============================] - 0s 272us/step - loss: 0.1545 - acc: 0.9583 - val_loss: 0.7384 - val_acc: 0.9167\n",
      "Epoch 161/200\n",
      "24/24 [==============================] - 0s 419us/step - loss: 0.1515 - acc: 0.9583 - val_loss: 0.7351 - val_acc: 0.9167\n",
      "Epoch 162/200\n",
      "24/24 [==============================] - 0s 383us/step - loss: 0.1495 - acc: 0.9583 - val_loss: 0.7351 - val_acc: 0.9167\n",
      "Epoch 163/200\n",
      "24/24 [==============================] - 0s 360us/step - loss: 0.1461 - acc: 0.9583 - val_loss: 0.7336 - val_acc: 0.9167\n",
      "Epoch 164/200\n",
      "24/24 [==============================] - 0s 401us/step - loss: 0.1435 - acc: 0.9583 - val_loss: 0.7314 - val_acc: 0.9167\n",
      "Epoch 165/200\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1418 - acc: 0.9583 - val_loss: 0.7272 - val_acc: 0.9167\n",
      "Epoch 166/200\n",
      "24/24 [==============================] - 0s 683us/step - loss: 0.1392 - acc: 0.9583 - val_loss: 0.7272 - val_acc: 0.9167\n",
      "Epoch 167/200\n",
      "24/24 [==============================] - 0s 812us/step - loss: 0.1358 - acc: 1.0000 - val_loss: 0.7255 - val_acc: 0.9167\n",
      "Epoch 168/200\n",
      "24/24 [==============================] - 0s 475us/step - loss: 0.1329 - acc: 1.0000 - val_loss: 0.7206 - val_acc: 0.9167\n",
      "Epoch 169/200\n",
      "24/24 [==============================] - 0s 486us/step - loss: 0.1307 - acc: 1.0000 - val_loss: 0.7208 - val_acc: 0.9167\n",
      "Epoch 170/200\n",
      "24/24 [==============================] - 0s 816us/step - loss: 0.1280 - acc: 1.0000 - val_loss: 0.7212 - val_acc: 0.9167\n",
      "Epoch 171/200\n",
      "24/24 [==============================] - 0s 725us/step - loss: 0.1272 - acc: 1.0000 - val_loss: 0.7191 - val_acc: 0.9167\n",
      "Epoch 172/200\n",
      "24/24 [==============================] - 0s 608us/step - loss: 0.1235 - acc: 1.0000 - val_loss: 0.7180 - val_acc: 0.9167\n",
      "Epoch 173/200\n",
      "24/24 [==============================] - 0s 547us/step - loss: 0.1206 - acc: 1.0000 - val_loss: 0.7171 - val_acc: 0.9167\n",
      "Epoch 174/200\n",
      "24/24 [==============================] - 0s 550us/step - loss: 0.1187 - acc: 1.0000 - val_loss: 0.7135 - val_acc: 0.9167\n",
      "Epoch 175/200\n",
      "24/24 [==============================] - 0s 679us/step - loss: 0.1164 - acc: 1.0000 - val_loss: 0.7128 - val_acc: 0.9167\n",
      "Epoch 176/200\n",
      "24/24 [==============================] - 0s 505us/step - loss: 0.1134 - acc: 1.0000 - val_loss: 0.7106 - val_acc: 0.9167\n",
      "Epoch 177/200\n",
      "24/24 [==============================] - 0s 502us/step - loss: 0.1113 - acc: 1.0000 - val_loss: 0.7116 - val_acc: 0.9167\n",
      "Epoch 178/200\n",
      "24/24 [==============================] - 0s 571us/step - loss: 0.1084 - acc: 1.0000 - val_loss: 0.7094 - val_acc: 0.9167\n",
      "Epoch 179/200\n",
      "24/24 [==============================] - 0s 445us/step - loss: 0.1065 - acc: 1.0000 - val_loss: 0.7080 - val_acc: 0.9167\n",
      "Epoch 180/200\n",
      "24/24 [==============================] - 0s 519us/step - loss: 0.1039 - acc: 1.0000 - val_loss: 0.7091 - val_acc: 0.9167\n",
      "Epoch 181/200\n",
      "24/24 [==============================] - 0s 414us/step - loss: 0.1015 - acc: 1.0000 - val_loss: 0.7100 - val_acc: 0.9167\n",
      "Epoch 182/200\n",
      "24/24 [==============================] - 0s 467us/step - loss: 0.0995 - acc: 1.0000 - val_loss: 0.7064 - val_acc: 0.9167\n",
      "Epoch 183/200\n",
      "24/24 [==============================] - 0s 389us/step - loss: 0.0965 - acc: 1.0000 - val_loss: 0.7045 - val_acc: 0.9167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/200\n",
      "24/24 [==============================] - 0s 431us/step - loss: 0.0942 - acc: 1.0000 - val_loss: 0.7043 - val_acc: 0.9167\n",
      "Epoch 185/200\n",
      "24/24 [==============================] - 0s 563us/step - loss: 0.0917 - acc: 1.0000 - val_loss: 0.7039 - val_acc: 0.9167\n",
      "Epoch 186/200\n",
      "24/24 [==============================] - 0s 408us/step - loss: 0.0907 - acc: 1.0000 - val_loss: 0.7024 - val_acc: 0.9167\n",
      "Epoch 187/200\n",
      "24/24 [==============================] - 0s 333us/step - loss: 0.0874 - acc: 1.0000 - val_loss: 0.7034 - val_acc: 0.9167\n",
      "Epoch 188/200\n",
      "24/24 [==============================] - 0s 313us/step - loss: 0.0854 - acc: 1.0000 - val_loss: 0.7043 - val_acc: 0.9167\n",
      "Epoch 189/200\n",
      "24/24 [==============================] - 0s 290us/step - loss: 0.0831 - acc: 1.0000 - val_loss: 0.7029 - val_acc: 0.9167\n",
      "Epoch 190/200\n",
      "24/24 [==============================] - 0s 386us/step - loss: 0.0809 - acc: 1.0000 - val_loss: 0.7020 - val_acc: 0.9167\n",
      "Epoch 191/200\n",
      "24/24 [==============================] - 0s 289us/step - loss: 0.0791 - acc: 1.0000 - val_loss: 0.7026 - val_acc: 0.9167\n",
      "Epoch 192/200\n",
      "24/24 [==============================] - 0s 291us/step - loss: 0.0770 - acc: 1.0000 - val_loss: 0.7011 - val_acc: 0.9167\n",
      "Epoch 193/200\n",
      "24/24 [==============================] - 0s 319us/step - loss: 0.0748 - acc: 1.0000 - val_loss: 0.7019 - val_acc: 0.9167\n",
      "Epoch 194/200\n",
      "24/24 [==============================] - 0s 383us/step - loss: 0.0725 - acc: 1.0000 - val_loss: 0.7032 - val_acc: 0.9167\n",
      "Epoch 195/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.0708 - acc: 1.0000 - val_loss: 0.7021 - val_acc: 0.9167\n",
      "Epoch 196/200\n",
      "24/24 [==============================] - 0s 542us/step - loss: 0.0688 - acc: 1.0000 - val_loss: 0.7019 - val_acc: 0.9167\n",
      "Epoch 197/200\n",
      "24/24 [==============================] - 0s 536us/step - loss: 0.0667 - acc: 1.0000 - val_loss: 0.7015 - val_acc: 0.9167\n",
      "Epoch 198/200\n",
      "24/24 [==============================] - 0s 497us/step - loss: 0.0659 - acc: 1.0000 - val_loss: 0.7023 - val_acc: 0.9167\n",
      "Epoch 199/200\n",
      "24/24 [==============================] - 0s 582us/step - loss: 0.0632 - acc: 1.0000 - val_loss: 0.7014 - val_acc: 0.9167\n",
      "Epoch 200/200\n",
      "24/24 [==============================] - 0s 461us/step - loss: 0.0614 - acc: 1.0000 - val_loss: 0.7033 - val_acc: 0.9167\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "history = model.fit(x_train,\n",
    "                    dummy_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=12,\n",
    "                    validation_data=(x_val, dummy_y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the logs above, the training accuracy is 100% and the validation accuracy is 91.67%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 4, 0, 0, 3, 4, 3, 4, 3, 1, 3])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(x_val), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 0, 3, 3, 4, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2\n",
    "\n",
    "### Using a simple 3-layer ANN with only text features (with text vectorized using Keras's text to matrix binary vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(df_train['expense description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 10000)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tfidf_keras = tokenizer.texts_to_matrix(df_train['expense description'], mode='binary')\n",
    "x_val_tfidf_keras = tokenizer.texts_to_matrix(df_val['expense description'], mode='binary')\n",
    "x_train_tfidf_keras.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 16)                160016    \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 160,373\n",
      "Trainable params: 160,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24 samples, validate on 12 samples\n",
      "Epoch 1/200\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.6093 - acc: 0.3750 - val_loss: 1.5909 - val_acc: 0.5000\n",
      "Epoch 2/200\n",
      "24/24 [==============================] - 0s 547us/step - loss: 1.5923 - acc: 0.4167 - val_loss: 1.5764 - val_acc: 0.6667\n",
      "Epoch 3/200\n",
      "24/24 [==============================] - 0s 772us/step - loss: 1.5797 - acc: 0.5833 - val_loss: 1.5647 - val_acc: 0.6667\n",
      "Epoch 4/200\n",
      "24/24 [==============================] - 0s 729us/step - loss: 1.5701 - acc: 0.6250 - val_loss: 1.5547 - val_acc: 0.6667\n",
      "Epoch 5/200\n",
      "24/24 [==============================] - 0s 842us/step - loss: 1.5604 - acc: 0.5833 - val_loss: 1.5448 - val_acc: 0.6667\n",
      "Epoch 6/200\n",
      "24/24 [==============================] - 0s 841us/step - loss: 1.5512 - acc: 0.6667 - val_loss: 1.5351 - val_acc: 0.6667\n",
      "Epoch 7/200\n",
      "24/24 [==============================] - 0s 836us/step - loss: 1.5421 - acc: 0.6667 - val_loss: 1.5246 - val_acc: 0.6667\n",
      "Epoch 8/200\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 1.5325 - acc: 0.7083 - val_loss: 1.5138 - val_acc: 0.6667\n",
      "Epoch 9/200\n",
      "24/24 [==============================] - 0s 882us/step - loss: 1.5224 - acc: 0.7083 - val_loss: 1.5022 - val_acc: 0.7500\n",
      "Epoch 10/200\n",
      "24/24 [==============================] - 0s 704us/step - loss: 1.5122 - acc: 0.7083 - val_loss: 1.4902 - val_acc: 0.7500\n",
      "Epoch 11/200\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 1.5012 - acc: 0.7083 - val_loss: 1.4778 - val_acc: 0.7500\n",
      "Epoch 12/200\n",
      "24/24 [==============================] - 0s 962us/step - loss: 1.4896 - acc: 0.7500 - val_loss: 1.4657 - val_acc: 0.7500\n",
      "Epoch 13/200\n",
      "24/24 [==============================] - 0s 583us/step - loss: 1.4781 - acc: 0.7917 - val_loss: 1.4535 - val_acc: 0.7500\n",
      "Epoch 14/200\n",
      "24/24 [==============================] - 0s 716us/step - loss: 1.4661 - acc: 0.7917 - val_loss: 1.4409 - val_acc: 0.7500\n",
      "Epoch 15/200\n",
      "24/24 [==============================] - 0s 600us/step - loss: 1.4540 - acc: 0.7917 - val_loss: 1.4280 - val_acc: 0.7500\n",
      "Epoch 16/200\n",
      "24/24 [==============================] - 0s 635us/step - loss: 1.4420 - acc: 0.7917 - val_loss: 1.4154 - val_acc: 0.7500\n",
      "Epoch 17/200\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 1.4302 - acc: 0.7917 - val_loss: 1.4033 - val_acc: 0.7500\n",
      "Epoch 18/200\n",
      "24/24 [==============================] - 0s 789us/step - loss: 1.4178 - acc: 0.7917 - val_loss: 1.3904 - val_acc: 0.7500\n",
      "Epoch 19/200\n",
      "24/24 [==============================] - 0s 700us/step - loss: 1.4056 - acc: 0.7917 - val_loss: 1.3777 - val_acc: 0.7500\n",
      "Epoch 20/200\n",
      "24/24 [==============================] - 0s 848us/step - loss: 1.3924 - acc: 0.7917 - val_loss: 1.3637 - val_acc: 0.7500\n",
      "Epoch 21/200\n",
      "24/24 [==============================] - 0s 787us/step - loss: 1.3796 - acc: 0.7917 - val_loss: 1.3494 - val_acc: 0.7500\n",
      "Epoch 22/200\n",
      "24/24 [==============================] - 0s 730us/step - loss: 1.3667 - acc: 0.7917 - val_loss: 1.3367 - val_acc: 0.7500\n",
      "Epoch 23/200\n",
      "24/24 [==============================] - 0s 912us/step - loss: 1.3532 - acc: 0.7917 - val_loss: 1.3224 - val_acc: 0.7500\n",
      "Epoch 24/200\n",
      "24/24 [==============================] - 0s 806us/step - loss: 1.3394 - acc: 0.7917 - val_loss: 1.3081 - val_acc: 0.7500\n",
      "Epoch 25/200\n",
      "24/24 [==============================] - 0s 898us/step - loss: 1.3266 - acc: 0.7917 - val_loss: 1.2941 - val_acc: 0.7500\n",
      "Epoch 26/200\n",
      "24/24 [==============================] - 0s 713us/step - loss: 1.3118 - acc: 0.7917 - val_loss: 1.2798 - val_acc: 0.7500\n",
      "Epoch 27/200\n",
      "24/24 [==============================] - 0s 777us/step - loss: 1.2975 - acc: 0.7917 - val_loss: 1.2657 - val_acc: 0.7500\n",
      "Epoch 28/200\n",
      "24/24 [==============================] - 0s 696us/step - loss: 1.2831 - acc: 0.7917 - val_loss: 1.2504 - val_acc: 0.7500\n",
      "Epoch 29/200\n",
      "24/24 [==============================] - 0s 877us/step - loss: 1.2693 - acc: 0.7917 - val_loss: 1.2344 - val_acc: 0.7500\n",
      "Epoch 30/200\n",
      "24/24 [==============================] - 0s 868us/step - loss: 1.2535 - acc: 0.7917 - val_loss: 1.2190 - val_acc: 0.7500\n",
      "Epoch 31/200\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 1.2384 - acc: 0.7917 - val_loss: 1.2038 - val_acc: 0.7500\n",
      "Epoch 32/200\n",
      "24/24 [==============================] - 0s 702us/step - loss: 1.2234 - acc: 0.8333 - val_loss: 1.1880 - val_acc: 0.7500\n",
      "Epoch 33/200\n",
      "24/24 [==============================] - 0s 736us/step - loss: 1.2078 - acc: 0.7917 - val_loss: 1.1720 - val_acc: 0.7500\n",
      "Epoch 34/200\n",
      "24/24 [==============================] - 0s 713us/step - loss: 1.1938 - acc: 0.8333 - val_loss: 1.1548 - val_acc: 0.7500\n",
      "Epoch 35/200\n",
      "24/24 [==============================] - 0s 577us/step - loss: 1.1755 - acc: 0.8333 - val_loss: 1.1386 - val_acc: 0.7500\n",
      "Epoch 36/200\n",
      "24/24 [==============================] - 0s 632us/step - loss: 1.1594 - acc: 0.8333 - val_loss: 1.1221 - val_acc: 0.8333\n",
      "Epoch 37/200\n",
      "24/24 [==============================] - 0s 678us/step - loss: 1.1428 - acc: 0.8750 - val_loss: 1.1061 - val_acc: 0.8333\n",
      "Epoch 38/200\n",
      "24/24 [==============================] - 0s 673us/step - loss: 1.1264 - acc: 0.8333 - val_loss: 1.0894 - val_acc: 0.8333\n",
      "Epoch 39/200\n",
      "24/24 [==============================] - 0s 865us/step - loss: 1.1109 - acc: 0.8750 - val_loss: 1.0730 - val_acc: 0.8333\n",
      "Epoch 40/200\n",
      "24/24 [==============================] - 0s 758us/step - loss: 1.0934 - acc: 0.8750 - val_loss: 1.0574 - val_acc: 0.8333\n",
      "Epoch 41/200\n",
      "24/24 [==============================] - 0s 624us/step - loss: 1.0763 - acc: 0.8750 - val_loss: 1.0424 - val_acc: 0.8333\n",
      "Epoch 42/200\n",
      "24/24 [==============================] - 0s 588us/step - loss: 1.0597 - acc: 0.8750 - val_loss: 1.0258 - val_acc: 0.8333\n",
      "Epoch 43/200\n",
      "24/24 [==============================] - 0s 982us/step - loss: 1.0425 - acc: 0.8750 - val_loss: 1.0114 - val_acc: 0.8333\n",
      "Epoch 44/200\n",
      "24/24 [==============================] - 0s 798us/step - loss: 1.0242 - acc: 0.8750 - val_loss: 0.9934 - val_acc: 0.8333\n",
      "Epoch 45/200\n",
      "24/24 [==============================] - 0s 668us/step - loss: 1.0063 - acc: 0.8750 - val_loss: 0.9766 - val_acc: 0.8333\n",
      "Epoch 46/200\n",
      "24/24 [==============================] - 0s 946us/step - loss: 0.9891 - acc: 0.8750 - val_loss: 0.9606 - val_acc: 0.8333\n",
      "Epoch 47/200\n",
      "24/24 [==============================] - 0s 780us/step - loss: 0.9704 - acc: 0.9167 - val_loss: 0.9451 - val_acc: 0.8333\n",
      "Epoch 48/200\n",
      "24/24 [==============================] - 0s 656us/step - loss: 0.9531 - acc: 0.9167 - val_loss: 0.9293 - val_acc: 0.8333\n",
      "Epoch 49/200\n",
      "24/24 [==============================] - 0s 893us/step - loss: 0.9366 - acc: 0.9167 - val_loss: 0.9141 - val_acc: 0.8333\n",
      "Epoch 50/200\n",
      "24/24 [==============================] - 0s 541us/step - loss: 0.9184 - acc: 0.9167 - val_loss: 0.8984 - val_acc: 0.8333\n",
      "Epoch 51/200\n",
      "24/24 [==============================] - 0s 656us/step - loss: 0.9012 - acc: 0.9583 - val_loss: 0.8836 - val_acc: 0.8333\n",
      "Epoch 52/200\n",
      "24/24 [==============================] - 0s 927us/step - loss: 0.8840 - acc: 0.9167 - val_loss: 0.8686 - val_acc: 0.8333\n",
      "Epoch 53/200\n",
      "24/24 [==============================] - 0s 787us/step - loss: 0.8662 - acc: 0.9583 - val_loss: 0.8538 - val_acc: 0.8333\n",
      "Epoch 54/200\n",
      "24/24 [==============================] - 0s 635us/step - loss: 0.8508 - acc: 0.9583 - val_loss: 0.8391 - val_acc: 0.8333\n",
      "Epoch 55/200\n",
      "24/24 [==============================] - 0s 586us/step - loss: 0.8339 - acc: 0.9583 - val_loss: 0.8239 - val_acc: 0.8333\n",
      "Epoch 56/200\n",
      "24/24 [==============================] - 0s 828us/step - loss: 0.8162 - acc: 0.9583 - val_loss: 0.8101 - val_acc: 0.8333\n",
      "Epoch 57/200\n",
      "24/24 [==============================] - 0s 596us/step - loss: 0.8004 - acc: 0.9583 - val_loss: 0.7967 - val_acc: 0.8333\n",
      "Epoch 58/200\n",
      "24/24 [==============================] - 0s 588us/step - loss: 0.7837 - acc: 0.9583 - val_loss: 0.7818 - val_acc: 0.8333\n",
      "Epoch 59/200\n",
      "24/24 [==============================] - 0s 606us/step - loss: 0.7673 - acc: 0.9583 - val_loss: 0.7684 - val_acc: 0.8333\n",
      "Epoch 60/200\n",
      "24/24 [==============================] - 0s 798us/step - loss: 0.7527 - acc: 0.9583 - val_loss: 0.7553 - val_acc: 0.8333\n",
      "Epoch 61/200\n",
      "24/24 [==============================] - 0s 759us/step - loss: 0.7364 - acc: 0.9583 - val_loss: 0.7425 - val_acc: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.7207 - acc: 0.9583 - val_loss: 0.7289 - val_acc: 0.8333\n",
      "Epoch 63/200\n",
      "24/24 [==============================] - 0s 746us/step - loss: 0.7050 - acc: 0.9583 - val_loss: 0.7160 - val_acc: 0.8333\n",
      "Epoch 64/200\n",
      "24/24 [==============================] - 0s 772us/step - loss: 0.6892 - acc: 0.9583 - val_loss: 0.7032 - val_acc: 0.8333\n",
      "Epoch 65/200\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.6745 - acc: 0.9583 - val_loss: 0.6910 - val_acc: 0.8333\n",
      "Epoch 66/200\n",
      "24/24 [==============================] - 0s 849us/step - loss: 0.6614 - acc: 0.9583 - val_loss: 0.6800 - val_acc: 0.9167\n",
      "Epoch 67/200\n",
      "24/24 [==============================] - 0s 812us/step - loss: 0.6449 - acc: 0.9583 - val_loss: 0.6678 - val_acc: 0.9167\n",
      "Epoch 68/200\n",
      "24/24 [==============================] - 0s 812us/step - loss: 0.6304 - acc: 1.0000 - val_loss: 0.6572 - val_acc: 0.9167\n",
      "Epoch 69/200\n",
      "24/24 [==============================] - 0s 925us/step - loss: 0.6159 - acc: 1.0000 - val_loss: 0.6446 - val_acc: 0.9167\n",
      "Epoch 70/200\n",
      "24/24 [==============================] - 0s 850us/step - loss: 0.6017 - acc: 1.0000 - val_loss: 0.6338 - val_acc: 0.9167\n",
      "Epoch 71/200\n",
      "24/24 [==============================] - 0s 678us/step - loss: 0.5887 - acc: 1.0000 - val_loss: 0.6241 - val_acc: 0.9167\n",
      "Epoch 72/200\n",
      "24/24 [==============================] - 0s 904us/step - loss: 0.5741 - acc: 1.0000 - val_loss: 0.6128 - val_acc: 0.9167\n",
      "Epoch 73/200\n",
      "24/24 [==============================] - 0s 844us/step - loss: 0.5600 - acc: 1.0000 - val_loss: 0.6023 - val_acc: 0.9167\n",
      "Epoch 74/200\n",
      "24/24 [==============================] - 0s 843us/step - loss: 0.5469 - acc: 1.0000 - val_loss: 0.5924 - val_acc: 0.9167\n",
      "Epoch 75/200\n",
      "24/24 [==============================] - 0s 805us/step - loss: 0.5334 - acc: 1.0000 - val_loss: 0.5823 - val_acc: 0.9167\n",
      "Epoch 76/200\n",
      "24/24 [==============================] - 0s 831us/step - loss: 0.5210 - acc: 1.0000 - val_loss: 0.5734 - val_acc: 0.9167\n",
      "Epoch 77/200\n",
      "24/24 [==============================] - 0s 989us/step - loss: 0.5075 - acc: 1.0000 - val_loss: 0.5628 - val_acc: 0.9167\n",
      "Epoch 78/200\n",
      "24/24 [==============================] - 0s 840us/step - loss: 0.4947 - acc: 1.0000 - val_loss: 0.5535 - val_acc: 0.9167\n",
      "Epoch 79/200\n",
      "24/24 [==============================] - 0s 695us/step - loss: 0.4827 - acc: 1.0000 - val_loss: 0.5441 - val_acc: 0.9167\n",
      "Epoch 80/200\n",
      "24/24 [==============================] - 0s 853us/step - loss: 0.4706 - acc: 1.0000 - val_loss: 0.5357 - val_acc: 0.9167\n",
      "Epoch 81/200\n",
      "24/24 [==============================] - 0s 768us/step - loss: 0.4585 - acc: 1.0000 - val_loss: 0.5271 - val_acc: 0.9167\n",
      "Epoch 82/200\n",
      "24/24 [==============================] - 0s 822us/step - loss: 0.4473 - acc: 1.0000 - val_loss: 0.5192 - val_acc: 0.9167\n",
      "Epoch 83/200\n",
      "24/24 [==============================] - 0s 661us/step - loss: 0.4347 - acc: 1.0000 - val_loss: 0.5104 - val_acc: 0.9167\n",
      "Epoch 84/200\n",
      "24/24 [==============================] - 0s 661us/step - loss: 0.4235 - acc: 1.0000 - val_loss: 0.5018 - val_acc: 0.9167\n",
      "Epoch 85/200\n",
      "24/24 [==============================] - 0s 696us/step - loss: 0.4141 - acc: 1.0000 - val_loss: 0.4952 - val_acc: 0.9167\n",
      "Epoch 86/200\n",
      "24/24 [==============================] - 0s 675us/step - loss: 0.4020 - acc: 1.0000 - val_loss: 0.4864 - val_acc: 0.9167\n",
      "Epoch 87/200\n",
      "24/24 [==============================] - 0s 740us/step - loss: 0.3908 - acc: 1.0000 - val_loss: 0.4800 - val_acc: 0.9167\n",
      "Epoch 88/200\n",
      "24/24 [==============================] - 0s 679us/step - loss: 0.3808 - acc: 1.0000 - val_loss: 0.4723 - val_acc: 0.9167\n",
      "Epoch 89/200\n",
      "24/24 [==============================] - 0s 639us/step - loss: 0.3705 - acc: 1.0000 - val_loss: 0.4647 - val_acc: 0.9167\n",
      "Epoch 90/200\n",
      "24/24 [==============================] - 0s 736us/step - loss: 0.3613 - acc: 1.0000 - val_loss: 0.4576 - val_acc: 0.9167\n",
      "Epoch 91/200\n",
      "24/24 [==============================] - 0s 765us/step - loss: 0.3513 - acc: 1.0000 - val_loss: 0.4507 - val_acc: 0.9167\n",
      "Epoch 92/200\n",
      "24/24 [==============================] - 0s 736us/step - loss: 0.3412 - acc: 1.0000 - val_loss: 0.4441 - val_acc: 0.9167\n",
      "Epoch 93/200\n",
      "24/24 [==============================] - 0s 722us/step - loss: 0.3318 - acc: 1.0000 - val_loss: 0.4378 - val_acc: 0.9167\n",
      "Epoch 94/200\n",
      "24/24 [==============================] - 0s 853us/step - loss: 0.3230 - acc: 1.0000 - val_loss: 0.4309 - val_acc: 0.9167\n",
      "Epoch 95/200\n",
      "24/24 [==============================] - 0s 705us/step - loss: 0.3136 - acc: 1.0000 - val_loss: 0.4254 - val_acc: 0.9167\n",
      "Epoch 96/200\n",
      "24/24 [==============================] - 0s 936us/step - loss: 0.3057 - acc: 1.0000 - val_loss: 0.4188 - val_acc: 0.9167\n",
      "Epoch 97/200\n",
      "24/24 [==============================] - 0s 816us/step - loss: 0.2971 - acc: 1.0000 - val_loss: 0.4136 - val_acc: 0.9167\n",
      "Epoch 98/200\n",
      "24/24 [==============================] - 0s 624us/step - loss: 0.2880 - acc: 1.0000 - val_loss: 0.4074 - val_acc: 0.9167\n",
      "Epoch 99/200\n",
      "24/24 [==============================] - 0s 883us/step - loss: 0.2798 - acc: 1.0000 - val_loss: 0.4016 - val_acc: 0.9167\n",
      "Epoch 100/200\n",
      "24/24 [==============================] - 0s 638us/step - loss: 0.2718 - acc: 1.0000 - val_loss: 0.3955 - val_acc: 0.9167\n",
      "Epoch 101/200\n",
      "24/24 [==============================] - 0s 839us/step - loss: 0.2640 - acc: 1.0000 - val_loss: 0.3900 - val_acc: 0.9167\n",
      "Epoch 102/200\n",
      "24/24 [==============================] - 0s 657us/step - loss: 0.2574 - acc: 1.0000 - val_loss: 0.3858 - val_acc: 0.9167\n",
      "Epoch 103/200\n",
      "24/24 [==============================] - 0s 976us/step - loss: 0.2490 - acc: 1.0000 - val_loss: 0.3801 - val_acc: 0.9167\n",
      "Epoch 104/200\n",
      "24/24 [==============================] - 0s 679us/step - loss: 0.2416 - acc: 1.0000 - val_loss: 0.3745 - val_acc: 0.9167\n",
      "Epoch 105/200\n",
      "24/24 [==============================] - 0s 815us/step - loss: 0.2343 - acc: 1.0000 - val_loss: 0.3707 - val_acc: 0.9167\n",
      "Epoch 106/200\n",
      "24/24 [==============================] - 0s 805us/step - loss: 0.2279 - acc: 1.0000 - val_loss: 0.3647 - val_acc: 0.9167\n",
      "Epoch 107/200\n",
      "24/24 [==============================] - 0s 784us/step - loss: 0.2210 - acc: 1.0000 - val_loss: 0.3601 - val_acc: 0.9167\n",
      "Epoch 108/200\n",
      "24/24 [==============================] - 0s 781us/step - loss: 0.2154 - acc: 1.0000 - val_loss: 0.3567 - val_acc: 0.9167\n",
      "Epoch 109/200\n",
      "24/24 [==============================] - 0s 828us/step - loss: 0.2082 - acc: 1.0000 - val_loss: 0.3511 - val_acc: 0.9167\n",
      "Epoch 110/200\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.2022 - acc: 1.0000 - val_loss: 0.3464 - val_acc: 0.9167\n",
      "Epoch 111/200\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1955 - acc: 1.0000 - val_loss: 0.3432 - val_acc: 0.9167\n",
      "Epoch 112/200\n",
      "24/24 [==============================] - 0s 735us/step - loss: 0.1905 - acc: 1.0000 - val_loss: 0.3390 - val_acc: 0.9167\n",
      "Epoch 113/200\n",
      "24/24 [==============================] - 0s 864us/step - loss: 0.1842 - acc: 1.0000 - val_loss: 0.3345 - val_acc: 0.9167\n",
      "Epoch 114/200\n",
      "24/24 [==============================] - 0s 705us/step - loss: 0.1792 - acc: 1.0000 - val_loss: 0.3316 - val_acc: 0.9167\n",
      "Epoch 115/200\n",
      "24/24 [==============================] - 0s 649us/step - loss: 0.1736 - acc: 1.0000 - val_loss: 0.3277 - val_acc: 0.9167\n",
      "Epoch 116/200\n",
      "24/24 [==============================] - 0s 812us/step - loss: 0.1689 - acc: 1.0000 - val_loss: 0.3228 - val_acc: 0.9167\n",
      "Epoch 117/200\n",
      "24/24 [==============================] - 0s 708us/step - loss: 0.1634 - acc: 1.0000 - val_loss: 0.3193 - val_acc: 0.9167\n",
      "Epoch 118/200\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.1584 - acc: 1.0000 - val_loss: 0.3161 - val_acc: 0.9167\n",
      "Epoch 119/200\n",
      "24/24 [==============================] - 0s 886us/step - loss: 0.1539 - acc: 1.0000 - val_loss: 0.3120 - val_acc: 0.9167\n",
      "Epoch 120/200\n",
      "24/24 [==============================] - 0s 716us/step - loss: 0.1493 - acc: 1.0000 - val_loss: 0.3082 - val_acc: 0.9167\n",
      "Epoch 121/200\n",
      "24/24 [==============================] - 0s 749us/step - loss: 0.1448 - acc: 1.0000 - val_loss: 0.3059 - val_acc: 0.9167\n",
      "Epoch 122/200\n",
      "24/24 [==============================] - 0s 745us/step - loss: 0.1404 - acc: 1.0000 - val_loss: 0.3018 - val_acc: 0.9167\n",
      "Epoch 123/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 666us/step - loss: 0.1366 - acc: 1.0000 - val_loss: 0.2996 - val_acc: 0.9167\n",
      "Epoch 124/200\n",
      "24/24 [==============================] - 0s 721us/step - loss: 0.1322 - acc: 1.0000 - val_loss: 0.2955 - val_acc: 0.9167\n",
      "Epoch 125/200\n",
      "24/24 [==============================] - 0s 609us/step - loss: 0.1282 - acc: 1.0000 - val_loss: 0.2919 - val_acc: 0.9167\n",
      "Epoch 126/200\n",
      "24/24 [==============================] - 0s 639us/step - loss: 0.1243 - acc: 1.0000 - val_loss: 0.2895 - val_acc: 0.9167\n",
      "Epoch 127/200\n",
      "24/24 [==============================] - 0s 918us/step - loss: 0.1208 - acc: 1.0000 - val_loss: 0.2859 - val_acc: 0.9167\n",
      "Epoch 128/200\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1169 - acc: 1.0000 - val_loss: 0.2835 - val_acc: 0.9167\n",
      "Epoch 129/200\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1134 - acc: 1.0000 - val_loss: 0.2800 - val_acc: 0.9167\n",
      "Epoch 130/200\n",
      "24/24 [==============================] - 0s 990us/step - loss: 0.1106 - acc: 1.0000 - val_loss: 0.2777 - val_acc: 0.9167\n",
      "Epoch 131/200\n",
      "24/24 [==============================] - 0s 899us/step - loss: 0.1071 - acc: 1.0000 - val_loss: 0.2742 - val_acc: 0.9167\n",
      "Epoch 132/200\n",
      "24/24 [==============================] - 0s 826us/step - loss: 0.1039 - acc: 1.0000 - val_loss: 0.2716 - val_acc: 0.9167\n",
      "Epoch 133/200\n",
      "24/24 [==============================] - 0s 915us/step - loss: 0.1006 - acc: 1.0000 - val_loss: 0.2686 - val_acc: 0.9167\n",
      "Epoch 134/200\n",
      "24/24 [==============================] - 0s 904us/step - loss: 0.0976 - acc: 1.0000 - val_loss: 0.2659 - val_acc: 0.9167\n",
      "Epoch 135/200\n",
      "24/24 [==============================] - 0s 873us/step - loss: 0.0947 - acc: 1.0000 - val_loss: 0.2628 - val_acc: 0.9167\n",
      "Epoch 136/200\n",
      "24/24 [==============================] - 0s 848us/step - loss: 0.0920 - acc: 1.0000 - val_loss: 0.2606 - val_acc: 0.9167\n",
      "Epoch 137/200\n",
      "24/24 [==============================] - 0s 887us/step - loss: 0.0891 - acc: 1.0000 - val_loss: 0.2565 - val_acc: 0.9167\n",
      "Epoch 138/200\n",
      "24/24 [==============================] - 0s 811us/step - loss: 0.0865 - acc: 1.0000 - val_loss: 0.2548 - val_acc: 0.9167\n",
      "Epoch 139/200\n",
      "24/24 [==============================] - 0s 717us/step - loss: 0.0838 - acc: 1.0000 - val_loss: 0.2525 - val_acc: 0.9167\n",
      "Epoch 140/200\n",
      "24/24 [==============================] - 0s 686us/step - loss: 0.0814 - acc: 1.0000 - val_loss: 0.2491 - val_acc: 0.9167\n",
      "Epoch 141/200\n",
      "24/24 [==============================] - 0s 788us/step - loss: 0.0789 - acc: 1.0000 - val_loss: 0.2476 - val_acc: 0.9167\n",
      "Epoch 142/200\n",
      "24/24 [==============================] - 0s 643us/step - loss: 0.0770 - acc: 1.0000 - val_loss: 0.2446 - val_acc: 0.9167\n",
      "Epoch 143/200\n",
      "24/24 [==============================] - 0s 854us/step - loss: 0.0747 - acc: 1.0000 - val_loss: 0.2427 - val_acc: 0.9167\n",
      "Epoch 144/200\n",
      "24/24 [==============================] - 0s 679us/step - loss: 0.0723 - acc: 1.0000 - val_loss: 0.2407 - val_acc: 0.9167\n",
      "Epoch 145/200\n",
      "24/24 [==============================] - 0s 814us/step - loss: 0.0704 - acc: 1.0000 - val_loss: 0.2377 - val_acc: 0.9167\n",
      "Epoch 146/200\n",
      "24/24 [==============================] - 0s 724us/step - loss: 0.0680 - acc: 1.0000 - val_loss: 0.2359 - val_acc: 0.9167\n",
      "Epoch 147/200\n",
      "24/24 [==============================] - 0s 779us/step - loss: 0.0661 - acc: 1.0000 - val_loss: 0.2326 - val_acc: 0.9167\n",
      "Epoch 148/200\n",
      "24/24 [==============================] - 0s 635us/step - loss: 0.0642 - acc: 1.0000 - val_loss: 0.2303 - val_acc: 0.9167\n",
      "Epoch 149/200\n",
      "24/24 [==============================] - 0s 787us/step - loss: 0.0624 - acc: 1.0000 - val_loss: 0.2288 - val_acc: 0.9167\n",
      "Epoch 150/200\n",
      "24/24 [==============================] - 0s 547us/step - loss: 0.0607 - acc: 1.0000 - val_loss: 0.2254 - val_acc: 0.9167\n",
      "Epoch 151/200\n",
      "24/24 [==============================] - 0s 857us/step - loss: 0.0587 - acc: 1.0000 - val_loss: 0.2229 - val_acc: 0.9167\n",
      "Epoch 152/200\n",
      "24/24 [==============================] - 0s 726us/step - loss: 0.0569 - acc: 1.0000 - val_loss: 0.2214 - val_acc: 0.9167\n",
      "Epoch 153/200\n",
      "24/24 [==============================] - 0s 652us/step - loss: 0.0556 - acc: 1.0000 - val_loss: 0.2186 - val_acc: 0.9167\n",
      "Epoch 154/200\n",
      "24/24 [==============================] - 0s 765us/step - loss: 0.0536 - acc: 1.0000 - val_loss: 0.2165 - val_acc: 0.9167\n",
      "Epoch 155/200\n",
      "24/24 [==============================] - 0s 925us/step - loss: 0.0520 - acc: 1.0000 - val_loss: 0.2138 - val_acc: 0.9167\n",
      "Epoch 156/200\n",
      "24/24 [==============================] - 0s 722us/step - loss: 0.0506 - acc: 1.0000 - val_loss: 0.2122 - val_acc: 0.9167\n",
      "Epoch 157/200\n",
      "24/24 [==============================] - 0s 729us/step - loss: 0.0489 - acc: 1.0000 - val_loss: 0.2083 - val_acc: 0.9167\n",
      "Epoch 158/200\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.0475 - acc: 1.0000 - val_loss: 0.2066 - val_acc: 0.9167\n",
      "Epoch 159/200\n",
      "24/24 [==============================] - 0s 775us/step - loss: 0.0461 - acc: 1.0000 - val_loss: 0.2048 - val_acc: 0.9167\n",
      "Epoch 160/200\n",
      "24/24 [==============================] - 0s 767us/step - loss: 0.0448 - acc: 1.0000 - val_loss: 0.2032 - val_acc: 0.9167\n",
      "Epoch 161/200\n",
      "24/24 [==============================] - 0s 644us/step - loss: 0.0434 - acc: 1.0000 - val_loss: 0.2000 - val_acc: 0.9167\n",
      "Epoch 162/200\n",
      "24/24 [==============================] - 0s 779us/step - loss: 0.0421 - acc: 1.0000 - val_loss: 0.1973 - val_acc: 0.9167\n",
      "Epoch 163/200\n",
      "24/24 [==============================] - 0s 782us/step - loss: 0.0407 - acc: 1.0000 - val_loss: 0.1950 - val_acc: 0.9167\n",
      "Epoch 164/200\n",
      "24/24 [==============================] - 0s 806us/step - loss: 0.0395 - acc: 1.0000 - val_loss: 0.1934 - val_acc: 0.9167\n",
      "Epoch 165/200\n",
      "24/24 [==============================] - 0s 582us/step - loss: 0.0384 - acc: 1.0000 - val_loss: 0.1919 - val_acc: 0.9167\n",
      "Epoch 166/200\n",
      "24/24 [==============================] - 0s 669us/step - loss: 0.0373 - acc: 1.0000 - val_loss: 0.1888 - val_acc: 0.9167\n",
      "Epoch 167/200\n",
      "24/24 [==============================] - 0s 742us/step - loss: 0.0359 - acc: 1.0000 - val_loss: 0.1876 - val_acc: 0.9167\n",
      "Epoch 168/200\n",
      "24/24 [==============================] - 0s 794us/step - loss: 0.0349 - acc: 1.0000 - val_loss: 0.1840 - val_acc: 0.9167\n",
      "Epoch 169/200\n",
      "24/24 [==============================] - 0s 712us/step - loss: 0.0338 - acc: 1.0000 - val_loss: 0.1827 - val_acc: 0.9167\n",
      "Epoch 170/200\n",
      "24/24 [==============================] - 0s 844us/step - loss: 0.0327 - acc: 1.0000 - val_loss: 0.1812 - val_acc: 0.9167\n",
      "Epoch 171/200\n",
      "24/24 [==============================] - 0s 680us/step - loss: 0.0316 - acc: 1.0000 - val_loss: 0.1794 - val_acc: 0.9167\n",
      "Epoch 172/200\n",
      "24/24 [==============================] - 0s 494us/step - loss: 0.0306 - acc: 1.0000 - val_loss: 0.1763 - val_acc: 0.9167\n",
      "Epoch 173/200\n",
      "24/24 [==============================] - 0s 635us/step - loss: 0.0299 - acc: 1.0000 - val_loss: 0.1748 - val_acc: 0.9167\n",
      "Epoch 174/200\n",
      "24/24 [==============================] - 0s 583us/step - loss: 0.0288 - acc: 1.0000 - val_loss: 0.1731 - val_acc: 0.9167\n",
      "Epoch 175/200\n",
      "24/24 [==============================] - 0s 586us/step - loss: 0.0281 - acc: 1.0000 - val_loss: 0.1703 - val_acc: 0.9167\n",
      "Epoch 176/200\n",
      "24/24 [==============================] - 0s 871us/step - loss: 0.0271 - acc: 1.0000 - val_loss: 0.1688 - val_acc: 0.9167\n",
      "Epoch 177/200\n",
      "24/24 [==============================] - 0s 689us/step - loss: 0.0262 - acc: 1.0000 - val_loss: 0.1676 - val_acc: 0.9167\n",
      "Epoch 178/200\n",
      "24/24 [==============================] - 0s 582us/step - loss: 0.0254 - acc: 1.0000 - val_loss: 0.1644 - val_acc: 0.9167\n",
      "Epoch 179/200\n",
      "24/24 [==============================] - 0s 833us/step - loss: 0.0245 - acc: 1.0000 - val_loss: 0.1631 - val_acc: 0.9167\n",
      "Epoch 180/200\n",
      "24/24 [==============================] - 0s 644us/step - loss: 0.0236 - acc: 1.0000 - val_loss: 0.1611 - val_acc: 0.9167\n",
      "Epoch 181/200\n",
      "24/24 [==============================] - 0s 550us/step - loss: 0.0229 - acc: 1.0000 - val_loss: 0.1586 - val_acc: 0.9167\n",
      "Epoch 182/200\n",
      "24/24 [==============================] - 0s 706us/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.1573 - val_acc: 0.9167\n",
      "Epoch 183/200\n",
      "24/24 [==============================] - 0s 684us/step - loss: 0.0213 - acc: 1.0000 - val_loss: 0.1547 - val_acc: 0.9167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/200\n",
      "24/24 [==============================] - 0s 585us/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.1535 - val_acc: 0.9167\n",
      "Epoch 185/200\n",
      "24/24 [==============================] - 0s 725us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.1521 - val_acc: 0.9167\n",
      "Epoch 186/200\n",
      "24/24 [==============================] - 0s 692us/step - loss: 0.0192 - acc: 1.0000 - val_loss: 0.1486 - val_acc: 0.9167\n",
      "Epoch 187/200\n",
      "24/24 [==============================] - 0s 529us/step - loss: 0.0187 - acc: 1.0000 - val_loss: 0.1475 - val_acc: 0.9167\n",
      "Epoch 188/200\n",
      "24/24 [==============================] - 0s 608us/step - loss: 0.0179 - acc: 1.0000 - val_loss: 0.1466 - val_acc: 0.9167\n",
      "Epoch 189/200\n",
      "24/24 [==============================] - 0s 618us/step - loss: 0.0173 - acc: 1.0000 - val_loss: 0.1443 - val_acc: 0.9167\n",
      "Epoch 190/200\n",
      "24/24 [==============================] - 0s 758us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.1434 - val_acc: 0.9167\n",
      "Epoch 191/200\n",
      "24/24 [==============================] - 0s 553us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.1425 - val_acc: 0.9167\n",
      "Epoch 192/200\n",
      "24/24 [==============================] - 0s 909us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.1393 - val_acc: 0.9167\n",
      "Epoch 193/200\n",
      "24/24 [==============================] - 0s 778us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.1379 - val_acc: 0.9167\n",
      "Epoch 194/200\n",
      "24/24 [==============================] - 0s 685us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.1371 - val_acc: 0.9167\n",
      "Epoch 195/200\n",
      "24/24 [==============================] - 0s 604us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.1361 - val_acc: 0.9167\n",
      "Epoch 196/200\n",
      "24/24 [==============================] - 0s 897us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.1338 - val_acc: 0.9167\n",
      "Epoch 197/200\n",
      "24/24 [==============================] - 0s 700us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.1325 - val_acc: 0.9167\n",
      "Epoch 198/200\n",
      "24/24 [==============================] - 0s 591us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.1305 - val_acc: 0.9167\n",
      "Epoch 199/200\n",
      "24/24 [==============================] - 0s 701us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.1287 - val_acc: 0.9167\n",
      "Epoch 200/200\n",
      "24/24 [==============================] - 0s 592us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.1263 - val_acc: 0.9167\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "history = model.fit(x_train_tfidf_keras,\n",
    "                    dummy_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=12,\n",
    "                    validation_data=(x_val_tfidf_keras, dummy_y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the logs above, the training accuracy is 100% and the validation accuracy is 91.67%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 3\n",
    "\n",
    "### Using a RNN with LSTM with a pre-trained embedding layer (GLOVE) and only text features (with text vectorized using Keras's text to matrix binary vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "glove_dir = 'glove.6B'\n",
    "embeddings_index = {}\n",
    "with open('glove.6B.100d.txt') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=500\n",
    "embedding_dimension=100\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "train_sequences = tokenizer.texts_to_sequences(df_train['expense description'])\n",
    "val_sequences = tokenizer.texts_to_sequences(df_val['expense description'])\n",
    "\n",
    "train_data = kreprocessing.sequence.pad_sequences(train_sequences, maxlen=max_len)\n",
    "val_data = kreprocessing.sequence.pad_sequences(val_sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 500)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000\n",
    "embedding_matrix = np.zeros((max_words, embedding_dimension))\n",
    "for word, i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 500, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 32)                17024     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 1,017,189\n",
      "Trainable params: 1,017,189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(max_words, embedding_dimension, input_length=max_len))\n",
    "model.add(layers.LSTM(32))\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24 samples, validate on 12 samples\n",
      "Epoch 1/20\n",
      "24/24 [==============================] - 3s 123ms/step - loss: 1.5062 - acc: 0.3750 - val_loss: 1.3186 - val_acc: 0.7500\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 1.2632 - acc: 0.7917 - val_loss: 1.1607 - val_acc: 0.8333\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 1.0976 - acc: 0.9167 - val_loss: 1.0268 - val_acc: 0.8333\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 2s 70ms/step - loss: 0.9557 - acc: 0.9167 - val_loss: 0.9094 - val_acc: 0.8333\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 2s 70ms/step - loss: 0.8403 - acc: 0.9167 - val_loss: 0.8069 - val_acc: 0.8333\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 2s 72ms/step - loss: 0.7366 - acc: 0.9167 - val_loss: 0.7196 - val_acc: 0.8333\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 2s 73ms/step - loss: 0.6395 - acc: 0.9167 - val_loss: 0.6425 - val_acc: 0.8333\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.5593 - acc: 0.9167 - val_loss: 0.5777 - val_acc: 0.8333\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 2s 72ms/step - loss: 0.4913 - acc: 0.9167 - val_loss: 0.5215 - val_acc: 0.8333\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.4267 - acc: 0.9167 - val_loss: 0.4744 - val_acc: 0.8333\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.3747 - acc: 0.9167 - val_loss: 0.4366 - val_acc: 0.8333\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 2s 68ms/step - loss: 0.3289 - acc: 0.9167 - val_loss: 0.4040 - val_acc: 0.8333\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 2s 70ms/step - loss: 0.2909 - acc: 0.9583 - val_loss: 0.3759 - val_acc: 0.8333\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 2s 70ms/step - loss: 0.2546 - acc: 0.9583 - val_loss: 0.3516 - val_acc: 0.8333\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 2s 73ms/step - loss: 0.2245 - acc: 0.9583 - val_loss: 0.3315 - val_acc: 0.9167\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 2s 73ms/step - loss: 0.1986 - acc: 0.9583 - val_loss: 0.3123 - val_acc: 0.9167\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.1746 - acc: 1.0000 - val_loss: 0.2954 - val_acc: 0.9167\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.1547 - acc: 1.0000 - val_loss: 0.2806 - val_acc: 0.9167\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.1366 - acc: 1.0000 - val_loss: 0.2674 - val_acc: 0.9167\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 2s 73ms/step - loss: 0.1216 - acc: 1.0000 - val_loss: 0.2544 - val_acc: 0.9167\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, dummy_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=6,\n",
    "                    validation_data=(val_data, dummy_y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the logs above, the training accuracy is 100% and the validation accuracy is 91.67%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
